{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahRGedwRMCxT",
    "outputId": "5c6d7163-a2f8-4904-c3e7-1953ffb2211a",
    "ExecuteTime": {
     "end_time": "2023-10-23T00:55:25.297527Z",
     "start_time": "2023-10-23T00:55:23.034500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (4.32.1)\r\n",
      "Requirement already satisfied: filelock in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\r\n",
      "Requirement already satisfied: requests in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-Kq9KJfMjZA",
    "outputId": "b28a3953-7a84-4a69-cf6f-35baad6cbae4",
    "ExecuteTime": {
     "end_time": "2023-10-23T00:55:27.900400Z",
     "start_time": "2023-10-23T00:55:25.851524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (0.1.99)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6VZyShZQ8YE",
    "outputId": "511e72d5-abaa-41fd-bcdf-f531628a4a5f",
    "ExecuteTime": {
     "end_time": "2023-10-23T00:55:29.964036Z",
     "start_time": "2023-10-23T00:55:27.901926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (0.23.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\r\n",
      "Requirement already satisfied: psutil in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (2.1.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from accelerate) (0.15.1)\r\n",
      "Requirement already satisfied: filelock in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\r\n",
      "Requirement already satisfied: sympy in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\r\n",
      "Requirement already satisfied: requests in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lucasanderson/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "# data_df = pd.read_excel(\"../StudentEssays.xlsx\")\n",
    "\n",
    "# Initialize T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# Move the model to the CUDA device if available\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "# Define a list of concepts to predict\n",
    "concepts_to_predict = [\"potential energy\", \"kinetic energy\", \"Law of Conservation of Energy\"]\n",
    "\n",
    "# Define possible outcome labels\n",
    "outcome_labels = [\"Acceptable\", \"Unacceptable\", \"Insufficient\"]\n",
    "\n",
    "# Create a list to store predictions as dictionaries\n",
    "predictions_list = []\n",
    "\n",
    "# Iterate through each row of text data\n",
    "# for index, row in data_df.iterrows():\n",
    "#     text = row['Essay']  # Assuming the text content is in column 'Essay'\n",
    "# \n",
    "#     # Initialize predictions dictionary for this row\n",
    "#     predictions = {}\n",
    "# \n",
    "#     # Iterate through each concept to predict\n",
    "#     for concept in concepts_to_predict:\n",
    "#         # Define a template for classification\n",
    "#         template = f\"According to the following essay, is the student's definition of {concept} Acceptable, Unacceptable, or Insufficient?\\n{text}\"\n",
    "# \n",
    "#         # Prepare the input by replacing placeholders\n",
    "#         formatted_input = template\n",
    "#         # Tokenize and classify the text\n",
    "#         input_ids = tokenizer(formatted_input, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         outputs = model.generate(input_ids, max_length=128)\n",
    "#         decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Remove special tokens\n",
    "# \n",
    "#         # Store the prediction in the dictionary\n",
    "#         predictions[concept] = next((label for label in outcome_labels if label in decoded_output), \"Unknown\")\n",
    "# \n",
    "#     # Append the predictions to the list\n",
    "#     predictions_list.append(predictions)\n",
    "# \n",
    "# # Convert the list of dictionaries to a DataFrame\n",
    "# predictions_df = pd.DataFrame(predictions_list)\n",
    "# \n",
    "# # # Print the predictions\n",
    "# # print(predictions_df)\n",
    "# # Set options to display all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# \n",
    "# # Print the predictions\n",
    "# print(predictions_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNXQ4U_w1dry",
    "outputId": "36589dcc-a764-4e57-93a6-fbc09674503e",
    "ExecuteTime": {
     "end_time": "2023-10-23T01:01:44.530725Z",
     "start_time": "2023-10-23T01:01:24.252433Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b706bd906bc546d2970da28a0e39c076"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c2bbab888734f1d81063d205662ac99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48a95be9ef884585b8912caf796c4207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67742ab737b74a7b8f3675bfd12435f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'potential energy': 'Insufficient',\n 'kinetic energy': 'Insufficient',\n 'Law of Conservation of Energy': 'Unknown'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(text):\n",
    "        \n",
    "    # Initialize predictions dictionary for this row\n",
    "    predictions = {}\n",
    "    \n",
    "    # Iterate through each concept to predict\n",
    "    for concept in concepts_to_predict:\n",
    "        # Define a template for classification\n",
    "        template = f\"According to the following essay, is the student's definition of {concept} Acceptable, Unacceptable, or Insufficient?\\n{text}\"\n",
    "    \n",
    "        # Prepare the input by replacing placeholders\n",
    "        formatted_input = template\n",
    "        # Tokenize and classify the text\n",
    "        input_ids = tokenizer(formatted_input, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        outputs = model.generate(input_ids, max_length=128)\n",
    "        decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Remove special tokens\n",
    "    \n",
    "        # Store the prediction in the dictionary\n",
    "        predictions[concept] = next((label for label in outcome_labels if label in decoded_output), \"Unknown\")\n",
    "    \n",
    "    # Append the predictions to the list\n",
    "    return predictions\n",
    "\n",
    "\n",
    "get_results(\"the law of conservation of energy states that total energy can change\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T01:21:37.591625Z",
     "start_time": "2023-10-23T01:21:37.190352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Update the original DataFrame with the predictions\n",
    "# data_df[\"PE\"] = predictions_df[\"potential energy\"]\n",
    "# data_df[\"KE\"] = predictions_df[\"kinetic energy\"]\n",
    "# data_df[\"LCE\"] = predictions_df[\"Law of Conservation of Energy\"]\n",
    "\n",
    "# Save the modified DataFrame to the same Excel file, overwriting the original file\n",
    "# data_df.to_excel(\"StudentEssays2.xlsx\", index=False)"
   ],
   "metadata": {
    "id": "ch7HBAWb9sh6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "outputId": "faf181b9-43c0-4285-eccd-722c100abe67",
    "ExecuteTime": {
     "end_time": "2023-10-22T21:23:59.066681Z",
     "start_time": "2023-10-22T21:23:59.060797Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
