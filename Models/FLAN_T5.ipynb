{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahRGedwRMCxT",
        "outputId": "14b44777-efb6-4286-f0bd-5aa14f72810a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-Kq9KJfMjZA",
        "outputId": "f91619da-8955-4c67-ce98-19e0b50e4bba"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6VZyShZQ8YE",
        "outputId": "c82a3d4c-cf5e-49b2-976a-413944a4d415"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/258.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/258.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Load data into pandas DataFrame\n",
        "data_df = pd.read_excel(\"StudentEssays.xlsx\")\n",
        "\n",
        "# Initialize T5 tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "# Move the model to the CUDA device if available\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "# Define a list of concepts to predict\n",
        "concepts_to_predict = [\"potential energy\", \"kinetic energy\", \"Law of Conservation of Energy\"]\n",
        "\n",
        "# Define possible outcome labels\n",
        "outcome_labels = [\"Acceptable\", \"Unacceptable\", \"Insufficient\", \"Not Found\"]\n",
        "\n",
        "# Create a list to store predictions as dictionaries\n",
        "predictions_list = []\n",
        "\n",
        "# Iterate through each row of text data\n",
        "for index, row in data_df.iterrows():\n",
        "    text = row['Essay']  # Assuming the text content is in column 'Essay'\n",
        "\n",
        "    # Initialize predictions dictionary for this row\n",
        "    predictions = {}\n",
        "\n",
        "    # Iterate through each concept to predict\n",
        "    for concept in concepts_to_predict:\n",
        "        # Define a template for classification\n",
        "        template = f\"According to the following essay, is the student's definition of {concept} Acceptable, Unacceptable, Insufficient, or Not Found? Only use one of these labels for outputs\\n{text}\"\n",
        "        # Prepare the input by replacing placeholders\n",
        "        formatted_input = template\n",
        "        # Tokenize and classify the text\n",
        "        input_ids = tokenizer(formatted_input, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        outputs = model.generate(input_ids, max_length=128)\n",
        "        decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Remove special tokens\n",
        "\n",
        "        # Store the prediction in the dictionary\n",
        "        predictions[concept] = next((label for label in outcome_labels if label.lower() in decoded_output.lower()), \"Unknown\")\n",
        "\n",
        "        if predictions[concept] == \"Unknown\":\n",
        "          print(len(decoded_output))\n",
        "          with open('output.txt', 'w') as f:\n",
        "            f.write(decoded_output)\n",
        "\n",
        "    # Append the predictions to the list\n",
        "    predictions_list.append(predictions)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "predictions_df = pd.DataFrame(predictions_list)\n",
        "\n",
        "# # Print the predictions\n",
        "# print(predictions_df)\n",
        "# Set options to display all rows and columns\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNXQ4U_w1dry",
        "outputId": "d42672eb-238e-4427-8067-188f6f1b26ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   potential energy kinetic energy Law of Conservation of Energy\n",
            "0         Not Found      Not Found                    Acceptable\n",
            "1         Not Found      Not Found                     Not Found\n",
            "2      Insufficient   Insufficient                    Acceptable\n",
            "3      Insufficient   Insufficient                  Insufficient\n",
            "4      Insufficient   Insufficient                    Acceptable\n",
            "5      Insufficient   Insufficient                     Not Found\n",
            "6         Not Found      Not Found                    Acceptable\n",
            "7      Insufficient   Insufficient                     Not Found\n",
            "8      Insufficient      Not Found                     Not Found\n",
            "9      Insufficient      Not Found                    Acceptable\n",
            "10     Insufficient   Insufficient                     Not Found\n",
            "11        Not Found      Not Found                     Not Found\n",
            "12     Insufficient   Insufficient                     Not Found\n",
            "13     Insufficient   Insufficient                    Acceptable\n",
            "14     Insufficient   Insufficient                    Acceptable\n",
            "15        Not Found      Not Found                     Not Found\n",
            "16        Not Found      Not Found                    Acceptable\n",
            "17        Not Found      Not Found                     Not Found\n",
            "18        Not Found   Insufficient                    Acceptable\n",
            "19        Not Found      Not Found                    Acceptable\n",
            "20        Not Found      Not Found                    Acceptable\n",
            "21     Insufficient   Insufficient                    Acceptable\n",
            "22     Insufficient   Insufficient                    Acceptable\n",
            "23        Not Found      Not Found                    Acceptable\n",
            "24     Insufficient   Insufficient                     Not Found\n",
            "25     Insufficient      Not Found                     Not Found\n",
            "26     Insufficient   Insufficient                  Insufficient\n",
            "27     Insufficient   Insufficient                    Acceptable\n",
            "28     Insufficient   Insufficient                    Acceptable\n",
            "29     Insufficient   Insufficient                    Acceptable\n",
            "30     Insufficient   Insufficient                    Acceptable\n",
            "31        Not Found      Not Found                    Acceptable\n",
            "32     Insufficient   Insufficient                    Acceptable\n",
            "33       Acceptable      Not Found                    Acceptable\n",
            "34     Insufficient   Insufficient                  Insufficient\n",
            "35        Not Found      Not Found                     Not Found\n",
            "36     Insufficient   Insufficient                  Insufficient\n",
            "37     Insufficient   Insufficient                    Acceptable\n",
            "38     Insufficient   Insufficient                  Insufficient\n",
            "39        Not Found      Not Found                    Acceptable\n",
            "40     Insufficient      Not Found                    Acceptable\n",
            "41        Not Found      Not Found                    Acceptable\n",
            "42        Not Found      Not Found                    Acceptable\n",
            "43     Insufficient      Not Found                    Acceptable\n",
            "44     Insufficient      Not Found                     Not Found\n",
            "45     Insufficient      Not Found                    Acceptable\n",
            "46     Insufficient      Not Found                    Acceptable\n",
            "47     Insufficient   Insufficient                     Not Found\n",
            "48     Insufficient   Insufficient                    Acceptable\n",
            "49        Not Found      Not Found                    Acceptable\n",
            "50     Insufficient   Insufficient                    Acceptable\n",
            "51     Insufficient   Insufficient                     Not Found\n",
            "52     Insufficient      Not Found                    Acceptable\n",
            "53     Insufficient      Not Found                    Acceptable\n",
            "54        Not Found      Not Found                    Acceptable\n",
            "55     Insufficient   Insufficient                    Acceptable\n",
            "56     Insufficient   Insufficient                    Acceptable\n",
            "57       Acceptable   Insufficient                    Acceptable\n",
            "58     Insufficient   Insufficient                    Acceptable\n",
            "59        Not Found      Not Found                    Acceptable\n",
            "60     Insufficient   Insufficient                    Acceptable\n",
            "61        Not Found      Not Found                     Not Found\n",
            "62     Insufficient      Not Found                     Not Found\n",
            "63        Not Found      Not Found                    Acceptable\n",
            "64     Insufficient   Insufficient                    Acceptable\n",
            "65     Insufficient   Insufficient                  Insufficient\n",
            "66     Insufficient   Insufficient                    Acceptable\n",
            "67     Insufficient   Insufficient                    Acceptable\n",
            "68     Insufficient      Not Found                    Acceptable\n",
            "69     Insufficient   Insufficient                  Insufficient\n",
            "70     Insufficient   Insufficient                    Acceptable\n",
            "71     Insufficient   Insufficient                  Insufficient\n",
            "72     Insufficient   Insufficient                  Insufficient\n",
            "73     Insufficient   Insufficient                    Acceptable\n",
            "74     Insufficient      Not Found                    Acceptable\n",
            "75     Insufficient      Not Found                     Not Found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UnxI34BZK4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the original DataFrame with the predictions\n",
        "data_df[\"PE\"] = predictions_df[\"potential energy\"]\n",
        "data_df[\"KE\"] = predictions_df[\"kinetic energy\"]\n",
        "data_df[\"LCE\"] = predictions_df[\"Law of Conservation of Energy\"]\n",
        "\n",
        "# Save the modified DataFrame to the same Excel file, overwriting the original file\n",
        "data_df.to_excel(\"Result.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "ch7HBAWb9sh6"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}